{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "generation_eval.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJo32IVxKXsn"
      },
      "source": [
        "!pip install semantic-text-similarity"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsTkfvnmKeWB"
      },
      "source": [
        "from semantic_text_similarity.models import WebBertSimilarity\n",
        "from semantic_text_similarity.models import ClinicalBertSimilarity\n",
        "\n",
        "web_model = WebBertSimilarity(device='cpu', batch_size=10) #defaults to GPU prediction\n",
        "\n",
        "# clinical_model = ClinicalBertSimilarity(device='cuda', batch_size=10) #defaults to GPU prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxCHMEgBKhGi"
      },
      "source": [
        "import numpy as np\n",
        "import pdb\n",
        "import json\n",
        "class GFG: \n",
        "  def __init__(self,graph): \n",
        "    self.graph = graph \n",
        "    self.ppl = len(graph) \n",
        "    self.jobs = len(graph[0]) \n",
        "\n",
        "  def bpm(self, u, matchR, seen): \n",
        "    for v in range(self.jobs):  \n",
        "      if self.graph[u][v] and seen[v] == False: \n",
        "        seen[v] = True\n",
        "        if matchR[v] == -1 or self.bpm(matchR[v], matchR, seen): \n",
        "          matchR[v] = u \n",
        "          return True\n",
        "    return False\n",
        "  \n",
        "  # Returns maximum number of matching \n",
        "  def maxBPM(self):\n",
        "    matchR = [-1] * self.jobs \n",
        "\n",
        "    result = 0\n",
        "    for i in range(self.ppl):\n",
        "      seen = [False] * self.jobs\n",
        "      if self.bpm(i, matchR, seen): \n",
        "        result += 1\n",
        "    return result, matchR\n",
        "\n",
        "def my_lcs(string, sub):\n",
        "  if(len(string)<= len(sub)):\n",
        "    sub, string = string, sub\n",
        "\n",
        "    lengths = [[0 for i in range(0,len(sub)+1)] for j in range(0,len(string)+1)]\n",
        "\n",
        "    for j in range(1,len(sub)+1):\n",
        "      for i in range(1,len(string)+1):\n",
        "        if (string[i-1] == sub[j-1]):\n",
        "          lengths[i][j] = lengths[i-1][j-1] + 1\n",
        "        else:\n",
        "          lengths[i][j] = max(lengths[i-1][j] , lengths[i][j-1])\n",
        "\n",
        "    return lengths[len(string)][len(sub)]\n",
        "\n",
        "class Rouge():\n",
        "  def __init__(self):\n",
        "    self.beta = 1.2\n",
        "\n",
        "  def calc_score(self, candidate, refs):\n",
        "    assert(len(candidate)==1)\t\n",
        "    assert(len(refs)>0)         \n",
        "    prec = []\n",
        "    rec = []\n",
        "\n",
        "  # split into tokens\n",
        "    token_c = candidate[0].split(\" \")\n",
        "    \t\n",
        "    for reference in refs:\n",
        "      # split into tokens\n",
        "      token_r = reference.split(\" \")\n",
        "      # compute the longest common subsequence\n",
        "      lcs = my_lcs(token_r, token_c)\n",
        "      if (lcs == None):\n",
        "        prec.append(0)\n",
        "        rec.append(0)\n",
        "      else:\n",
        "        prec.append(lcs/float(len(token_c)))\n",
        "        rec.append(lcs/float(len(token_r)))\n",
        "\n",
        "      prec_max = max(prec)\n",
        "      rec_max = max(rec)\n",
        "\n",
        "      if (prec_max!=0 and rec_max !=0):\n",
        "        score = ((1 + self.beta**2)*prec_max*rec_max)/float(rec_max + self.beta**2*prec_max)\n",
        "      else:\n",
        "        score = 0.0\n",
        "      return score\n",
        "\n",
        "  def compute_score(self, refs, test):\n",
        "    score = []\n",
        "    for i in range(len(refs)):\n",
        "      hypo = test[i]\n",
        "      ref = refs[i]\n",
        "      if (hypo == \" \" or hypo == \"\"):\n",
        "        score.append(0)\n",
        "      else:\n",
        "        score.append(self.calc_score([hypo], [ref]))\n",
        "    \n",
        "    average_score = np.mean(np.array(score))\n",
        "    return average_score, np.array(score)\n",
        "\n",
        "  def method(self):\n",
        "    return \"Rouge\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LaH9bWlv13Dq"
      },
      "source": [
        "For evaluation of property generation models XGP and XGP-W"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNIt698VKi1W"
      },
      "source": [
        "f = open('./GPT_Multiple_Output/gpt2_raw_output.json')\n",
        "data = json.load(f)\n",
        "name = 'gpt2_raw_output'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLzLpT5eKl9H"
      },
      "source": [
        "import json\n",
        "\n",
        "sts_predictions_array = []\n",
        "sts_predictions_array2 = []\n",
        "positive_indices = []\n",
        "negative_indices = []\n",
        "sts_recall = 0.0\n",
        "sts_precision = 0.0\n",
        "sts_fscore = 0.0\n",
        "count = 0\n",
        "sts_threshold = 3\n",
        "\n",
        "counter = []\n",
        "for k in range(len(data[\"Input\"])):\n",
        "  if (k % 500 == 0):\n",
        "    print(k)\n",
        "  l1 = data[\"Gold\"][k]\n",
        "  l2 = data[\"Output\"][k]\n",
        "  if data[\"Correctness\"][k]:\n",
        "    positive_indices.append(k)\n",
        "    # l2 = data[\"Output\"][k]\n",
        "  else:\n",
        "    negative_indices.append(k)\n",
        "    # l2 = [data[\"Output\"][k][0]]\n",
        "  bipartite_graph = np.zeros((len(l1), len(l2)))\n",
        "  bipartite_graph_double = np.zeros((len(l1), len(l2)))\n",
        "  \n",
        "  for i in range(len(l1)):\n",
        "    for j in range(len(l2)):\n",
        "      sts_score = web_model.predict([(l1[i], l2[j])])[0]\n",
        "      bipartite_graph_double[i][j] = sts_score\n",
        "      if (sts_score >= sts_threshold):\n",
        "        bipartite_graph[i][j] = 1\n",
        "      else:\n",
        "        bipartite_graph[i][j] = 0\n",
        "\n",
        "  g = GFG(bipartite_graph_double) \n",
        "  number, division_list = g.maxBPM()\n",
        "\n",
        "  # property i will be matched with division_list[i]  change this comment\n",
        "  score0 = 0\n",
        "  for i in range(len(l1)):\n",
        "    j = -1\n",
        "    for k in range(len(division_list)):\n",
        "      if(division_list[k] == i):\n",
        "        j = k\n",
        "        break\n",
        "\n",
        "    if (j != -1):\n",
        "      sts_score = bipartite_graph_double[i][j]\n",
        "      score0 += sts_score\n",
        "      count += 1\n",
        "      counter.append(count)\n",
        "      sts_predictions_array2.append(sts_score)\n",
        "      \n",
        "    else:\n",
        "      count += 1\n",
        "      sts_predictions_array2.append(0)\n",
        "\n",
        "  sts_predictions_array.append(score0/len(l1))\n",
        "\n",
        "  g = GFG(bipartite_graph) \n",
        "  number, division_list = g.maxBPM()\n",
        "\n",
        "  # property i will be matched with division_list[i]  change this comment\n",
        "  score_recall0 = 0\n",
        "  score_precision0 = 0\n",
        "  for i in range(len(l1)):\n",
        "    j = -1\n",
        "    for k in range(len(division_list)):\n",
        "      if(division_list[k] == i):\n",
        "        j = k\n",
        "        break\n",
        "\n",
        "    if (j != -1):\n",
        "      score_recall0 += 1\n",
        "      score_precision0 += 1\n",
        "      count += 1\n",
        "    else:\n",
        "      count += 1\n",
        "  sts_recall += score_recall0/len(l1)\n",
        "  sts_precision += score_precision0/len(l2)\n",
        "  a0 = score_recall0/len(l1)\n",
        "  b0 = score_precision0/len(l2)\n",
        "  if (a0+b0 != 0):\n",
        "    sts_fscore += 2*a0*b0/(a0+b0)\n",
        "\n",
        "# print(count)\n",
        "# print(len(counter))\n",
        "x = len(data[\"Input\"])\n",
        "print(\"STS Score==============\")\n",
        "print(sts_recall/x)\n",
        "print(sts_precision/x)\n",
        "print(sts_fscore/x)\n",
        "# print(np.average(sts_predictions_array)/5)\n",
        "# predictions_positive = [sts_predictions_array[i] for i in positive_indices]\n",
        "# predictions_negative = [sts_predictions_array[i] for i in negative_indices]\n",
        "# print(np.average(predictions_positive)/5)\n",
        "# print(np.average(predictions_negative)/5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZdWAcEiK7gf"
      },
      "source": [
        "spice_thresholder = []\n",
        "cider_refs_thresholder = []\n",
        "cider_test_thresholder = []\n",
        "count = 0\n",
        "for k in range(len(data[\"Input\"])):\n",
        "  # if (k % 500 == 0):\n",
        "  #   print(k)\n",
        "  l1 = data[\"Gold\"][k]\n",
        "  l2 = data[\"Output\"][k]\n",
        "  # correctness = data[\"Correctness\"][k]\n",
        "  # if not correctness:\n",
        "  #   l2 = [data[\"Output\"][k][0]]\n",
        "  # else:\n",
        "  #   l2 = data[\"Output\"][k]\n",
        "  for i in range(len(l1)):\n",
        "    for j in range(len(l2)):\n",
        "      struct = {\n",
        "          \"image_id\": count,\n",
        "          \"caption\": l2[j]\n",
        "      }\n",
        "      cider_test_thresholder.append(struct)\n",
        "      struct = {\n",
        "          \"image_id\": count,\n",
        "          \"caption\": l1[i]\n",
        "      }\n",
        "      cider_refs_thresholder.append(struct)\n",
        "      struct = {\n",
        "          \"image_id\": count,\n",
        "          \"test\": l2[j],\n",
        "          \"refs\": [l1[i]]\n",
        "      }\n",
        "      spice_thresholder.append(struct)\n",
        "      count += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLVuDoBtLDLG"
      },
      "source": [
        "%cd cider/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gqgl3piiK8Qp"
      },
      "source": [
        "with open('./data/cider_' + name + '_refs.json', 'w') as outfile:\n",
        "    json.dump(cider_refs_thresholder, outfile)\n",
        "with open('./data/cider_' + name + '_test.json', 'w') as outfile:\n",
        "    json.dump(cider_test_thresholder, outfile)\n",
        "with open('../spice/spice_' + name + '.json', 'w') as outfile:\n",
        "    json.dump(spice_thresholder, outfile)\n",
        "\n",
        "params = {\n",
        "  \"pathToData\" : \"data/\",\n",
        "\t\"refName\" : 'cider_' + name + '_refs.json',\n",
        "\t\"candName\" : 'cider_' + name + '_test.json',\n",
        "\t\"resultFile\" : 'cider_' + name + '_results.json',\n",
        "\t\"idf\" : \"coco-val-df\"\n",
        "}\n",
        "with open('params.json', 'w') as outfile:\n",
        "    json.dump(params, outfile)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIqxxiUdLFaL"
      },
      "source": [
        "!python2 cidereval.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMks1Ka-LIeb"
      },
      "source": [
        "file2 = open('./cider_' + name + '_results.json')\n",
        "cider_output = json.load(file2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwGgq7OsLKI1"
      },
      "source": [
        "%cd ../meteor/\n",
        "write_file = open(name + \"_meteor_refs\", \"w\")\n",
        "for i in range(len(cider_refs_thresholder)):\n",
        "  new_line = cider_refs_thresholder[i]['caption'].replace(\"\\n\", \" \") + \" \\n\"\n",
        "  write_file.write(new_line)\n",
        "write_file.close()\n",
        "\n",
        "write_file2 = open(name + \"_meteor_test\", \"w\")\n",
        "for i in range(len(cider_test_thresholder)):\n",
        "  if (cider_test_thresholder[i]['caption'] == \"\" or cider_test_thresholder[i]['caption'] == \" \"):\n",
        "    new_line = \"empty \\n\"\n",
        "  else:\n",
        "    new_line = cider_test_thresholder[i]['caption'].replace(\"\\n\", \" \") + \" \\n\"\n",
        "  write_file2.write(new_line)\n",
        "write_file2.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pE1skD4XLOnt"
      },
      "source": [
        "meteor_scores = !java -Xmx2G -jar meteor-1.5.jar ./gpt2_raw_output_meteor_test ./gpt2_raw_output_meteor_refs -l en -norm -a data/paraphrase-en.gz -q\n",
        "meteor_scores = [float(meteor_scores[i]) for i in range(len(meteor_scores))]\n",
        "meteor_scores[-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1W--0hehLQXT"
      },
      "source": [
        "%cd ../spice/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzGsT2DgLUF1"
      },
      "source": [
        "#in spice directory\n",
        "!java -Xmx8G -jar spice-1.0.jar spice_gpt2_raw_output.json -cache ./cache -out spice_gpt2_raw_output_output.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbOIAsnSLVH2"
      },
      "source": [
        "file2 = open('./spice_' + name + '_output.json')\n",
        "spice_output = json.load(file2)\n",
        "len(spice_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DL1h96VLX-m"
      },
      "source": [
        "rouge_test =  [cider_test_thresholder[i]['caption'] for i in range(len(cider_test_thresholder))]\n",
        "rouge_refs =  [cider_refs_thresholder[i]['caption'] for i in range(len(cider_refs_thresholder))]\n",
        "r = Rouge()\n",
        "rouge_scores = r.compute_score(rouge_refs, rouge_test)\n",
        "rouge_scores[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmKVN-gxLZqq"
      },
      "source": [
        "import json\n",
        "\n",
        "spice_recall = 0.0\n",
        "spice_precision = 0.0\n",
        "spice_fscore = 0.0\n",
        "cider_recall = 0.0\n",
        "cider_precision = 0.0\n",
        "cider_fscore = 0.0\n",
        "meteor_recall = 0.0\n",
        "meteor_precision = 0.0\n",
        "meteor_fscore = 0.0\n",
        "rouge_recall = 0.0\n",
        "rouge_precision = 0.0\n",
        "rouge_fscore = 0.0\n",
        "count1 = 0\n",
        "count = 0\n",
        "spice_threshold = 0.4\n",
        "cider_threshold = 3\n",
        "meteor_threshold = 0.3\n",
        "rouge_threshold = 0.3\n",
        "counter = []\n",
        "for k in range(len(data[\"Input\"])):\n",
        "  if (k % 500 == 0):\n",
        "    print(k)\n",
        "  l1 = data[\"Gold\"][k]\n",
        "  l2 = data[\"Output\"][k]\n",
        "  \n",
        "  bipartite_graph = np.zeros((len(l1), len(l2)))\n",
        "  bipartite_graph_double_spice = np.zeros((len(l1), len(l2)))\n",
        "  bipartite_graph_double_meteor = np.zeros((len(l1), len(l2)))\n",
        "  bipartite_graph_double_rouge = np.zeros((len(l1), len(l2)))\n",
        "  \n",
        "  for i in range(len(l1)):\n",
        "    for j in range(len(l2)):\n",
        "      cider_score = cider_output['CIDEr'][count1]\n",
        "      meteor_score = meteor_scores[count1]\n",
        "      rouge_score = rouge_scores[1][count1]\n",
        "      spice_score = spice_output[count1]['scores']['All']['f']\n",
        "      count1 += 1\n",
        "      if (spice_score >= spice_threshold):\n",
        "        bipartite_graph_double_spice[i][j] = 1\n",
        "      else:\n",
        "        bipartite_graph_double_spice[i][j] = 0\n",
        "      if (cider_score >= cider_threshold):\n",
        "        bipartite_graph[i][j] = 1\n",
        "      else:\n",
        "        bipartite_graph[i][j] = 0\n",
        "      if (meteor_score >= meteor_threshold):\n",
        "        bipartite_graph_double_meteor[i][j] = 1\n",
        "      else:\n",
        "        bipartite_graph_double_meteor[i][j] = 0\n",
        "      if (rouge_score >= rouge_threshold):\n",
        "        bipartite_graph_double_rouge[i][j] = 1\n",
        "      else:\n",
        "        bipartite_graph_double_rouge[i][j] = 0\n",
        "\n",
        "  g = GFG(bipartite_graph_double_spice)\n",
        "  number, division_list = g.maxBPM()\n",
        "  \n",
        "  score_recall1 = 0\n",
        "  score_precision1 = 0\n",
        "  for i in range(len(l1)):\n",
        "    j = -1\n",
        "    for k in range(len(division_list)):\n",
        "      if (division_list[k] == i):\n",
        "        j = k\n",
        "        break\n",
        "    \n",
        "    if (j != -1):\n",
        "      score_recall1 += 1\n",
        "      score_precision1 += 1\n",
        "      count += 1\n",
        "    else:\n",
        "      count += 1\n",
        "\n",
        "  spice_recall += score_recall1/len(l1)\n",
        "  spice_precision += score_precision1/len(l2)\n",
        "  a1 = score_recall1/len(l1)\n",
        "  b1 = score_precision1/len(l2)\n",
        "  if (a1+b1 != 0):\n",
        "    spice_fscore += 2*a1*b1/(a1+b1)\n",
        "\n",
        "  g = GFG(bipartite_graph)\n",
        "  number, division_list = g.maxBPM()\n",
        "  \n",
        "  score_recall2 = 0\n",
        "  score_precision2 = 0\n",
        "  for i in range(len(l1)):\n",
        "    j = -1\n",
        "    for k in range(len(division_list)):\n",
        "      if (division_list[k] == i):\n",
        "        j = k\n",
        "        break\n",
        "    \n",
        "    if (j != -1):\n",
        "      score_recall2 += 1\n",
        "      score_precision2 += 1\n",
        "      count += 1 \n",
        "    else:\n",
        "      count += 1\n",
        "\n",
        "  cider_recall += score_recall2/len(l1)\n",
        "  cider_precision += score_precision2/len(l2)\n",
        "  a2 = score_recall2/len(l1)\n",
        "  b2 = score_precision2/len(l2)\n",
        "  if (a2+b2 != 0):\n",
        "    cider_fscore += 2*a2*b2/(a2+b2)\n",
        "\n",
        "  g = GFG(bipartite_graph_double_meteor) \n",
        "  number, division_list = g.maxBPM()\n",
        "  \n",
        "  score_recall3 = 0\n",
        "  score_precision3 = 0\n",
        "  for i in range(len(l1)):\n",
        "    j = -1\n",
        "    for k in range(len(division_list)):\n",
        "      if (division_list[k] == i):\n",
        "        j = k\n",
        "        break\n",
        "    if (j != -1):\n",
        "      score_recall3 += 1\n",
        "      score_precision3 += 1\n",
        "      count += 1 \n",
        "    else:\n",
        "      count += 1\n",
        "  meteor_recall += score_recall3/len(l1)\n",
        "  meteor_precision += score_precision3/len(l2)\n",
        "  a2 = score_recall3/len(l1)\n",
        "  b2 = score_precision3/len(l2)\n",
        "  if (a2+b2 != 0):\n",
        "    meteor_fscore += 2*a2*b2/(a2+b2)\n",
        "\n",
        "  g = GFG(bipartite_graph_double_rouge) \n",
        "  number, division_list = g.maxBPM()\n",
        "  \n",
        "  score_recall4 = 0\n",
        "  score_precision4 = 0\n",
        "  for i in range(len(l1)):\n",
        "    j = -1\n",
        "    for k in range(len(division_list)):\n",
        "      if (division_list[k] == i):\n",
        "        j = k\n",
        "        break\n",
        "    if (j != -1):\n",
        "      score_recall4 += 1\n",
        "      score_precision4 += 1\n",
        "      count += 1 \n",
        "    else:\n",
        "      count += 1\n",
        "  rouge_recall += score_recall4/len(l1)\n",
        "  rouge_precision += score_precision4/len(l2)\n",
        "  a2 = score_recall4/len(l1)\n",
        "  b2 = score_precision4/len(l2)\n",
        "  if (a2+b2 != 0):\n",
        "    rouge_fscore += 2*a2*b2/(a2+b2)\n",
        "\n",
        "x = len(data[\"Input\"])\n",
        "print(\"SPICE==============\")\n",
        "print(spice_recall/x)\n",
        "print(spice_precision/x)\n",
        "print(spice_fscore/x)\n",
        "print(\"CIDEr==============\")\n",
        "print(cider_recall/x)\n",
        "print(cider_precision/x)\n",
        "print(cider_fscore/x)\n",
        "print(\"METEOR==============\")\n",
        "print(meteor_recall/x)\n",
        "print(meteor_precision/x)\n",
        "print(meteor_fscore/x)\n",
        "print(\"ROUGE==============\")\n",
        "print(rouge_recall/x)\n",
        "print(rouge_precision/x)\n",
        "print(rouge_fscore/x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2opCekB50g1_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fm-jKoiB1oR9"
      },
      "source": [
        "For evaluation of free-flow generation models XGF-I and XGF-II"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9o8mEghB0hOZ"
      },
      "source": [
        "import json\n",
        "f = open('../GPT_Multiple_Output/gpt2_raw_freeflow_output.json')\n",
        "data = json.load(f)\n",
        "name = \"gpt2_raw_freeflow_output\"\n",
        "\n",
        "spice_thresholder = []\n",
        "cider_refs_thresholder = []\n",
        "cider_test_thresholder = []\n",
        "count = 0\n",
        "for k in range(len(data[\"input\"])):\n",
        "  # if (k % 500 == 0):\n",
        "  #   print(k)\n",
        "  l1 = data[\"gold\"][k].replace(\"<EOS>\",\"\")\n",
        "  l2 = data[\"output\"][k]\n",
        "  # l1 = gold[k]\n",
        "  # l2 = prime[k]\n",
        "  struct = {\n",
        "      \"image_id\": count,\n",
        "      \"caption\": l2\n",
        "      }\n",
        "  cider_test_thresholder.append(struct)\n",
        "  struct = {\n",
        "      \"image_id\": count,\n",
        "      \"caption\": l1\n",
        "  }\n",
        "  cider_refs_thresholder.append(struct)\n",
        "  struct = {\n",
        "      \"image_id\": count,\n",
        "      \"test\": l2,\n",
        "      \"refs\": [l1]\n",
        "  }\n",
        "  spice_thresholder.append(struct)\n",
        "  count += 1\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXxKDmAK0nW2"
      },
      "source": [
        "%cd ../cider"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtFfDIpN0yBb"
      },
      "source": [
        "with open('./data/cider_' + name + '_refs.json', 'w') as outfile:\n",
        "    json.dump(cider_refs_thresholder, outfile)\n",
        "with open('./data/cider_' + name + '_test.json', 'w') as outfile:\n",
        "    json.dump(cider_test_thresholder, outfile)\n",
        "with open('../spice/spice_' + name + '.json', 'w') as outfile:\n",
        "    json.dump(spice_thresholder, outfile)\n",
        "\n",
        "params = {\n",
        "  \"pathToData\" : \"data/\",\n",
        "\t\"refName\" : 'cider_' + name + '_refs.json',\n",
        "\t\"candName\" : 'cider_' + name + '_test.json',\n",
        "\t\"resultFile\" : 'cider_' + name + '_results.json',\n",
        "\t\"idf\" : \"coco-val-df\"\n",
        "}\n",
        "with open('params.json', 'w') as outfile:\n",
        "    json.dump(params, outfile)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSbG7viB02Hb"
      },
      "source": [
        "!python2 cidereval.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFhKdaL404Il"
      },
      "source": [
        "file2 = open('./cider_' + name + '_results.json')\n",
        "cider_output = json.load(file2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDltrQ7e06av"
      },
      "source": [
        "%cd ../spice/\n",
        "write_file = open(name + \"_meteor_refs\", \"w\")\n",
        "for i in range(len(cider_refs_thresholder)):\n",
        "  new_line = cider_refs_thresholder[i]['caption'].replace(\"\\n\", \" \") + \" \\n\"\n",
        "  write_file.write(new_line)\n",
        "write_file.close()\n",
        "\n",
        "write_file2 = open(name + \"_meteor_test\", \"w\")\n",
        "for i in range(len(cider_test_thresholder)):\n",
        "  if (cider_test_thresholder[i]['caption'] == \"\" or cider_test_thresholder[i]['caption'] == \" \"):\n",
        "    new_line = \"empty \\n\"\n",
        "  else:\n",
        "    new_line = cider_test_thresholder[i]['caption'].replace(\"\\n\", \" \") + \" \\n\"\n",
        "  write_file2.write(new_line)\n",
        "write_file2.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zs6KhufQ087h"
      },
      "source": [
        "meteor_scores = !java -Xmx2G -jar meteor-1.5.jar ./gpt2_raw_freeflow_output_meteor_test ./gpt2_raw_freeflow_output_meteor_refs -l en -norm -a data/paraphrase-en.gz -q\n",
        "meteor_scores = [float(meteor_scores[i]) for i in range(len(meteor_scores))]\n",
        "meteor_scores[-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBM7npIk1EYK"
      },
      "source": [
        "#in spice directory\n",
        "!java -Xmx8G -jar spice-1.0.jar spice_gpt2_raw_freeflow_output.json -cache ./cache2 -out spice_gpt2_raw_freeflow_output_output.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Khg9ENq1JrS"
      },
      "source": [
        "file2 = open('./spice_' + name + '_output.json')\n",
        "spice_output = json.load(file2)\n",
        "len(spice_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhQRvm7e1N-u"
      },
      "source": [
        "rouge_test =  [cider_test_thresholder[i]['caption'] for i in range(len(cider_test_thresholder))]\n",
        "rouge_refs =  [cider_refs_thresholder[i]['caption'] for i in range(len(cider_refs_thresholder))]\n",
        "r = Rouge()\n",
        "rouge_scores = r.compute_score(rouge_refs, rouge_test)\n",
        "rouge_scores[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBbdU42S1Pta"
      },
      "source": [
        "import json\n",
        "import numpy as np\n",
        "spice_predictions_array = []\n",
        "cider_predictions_array = []\n",
        "meteor_predictions_array = []\n",
        "rouge_predictions_array = []\n",
        "counter = []\n",
        "for k in range(len(spice_output)):\n",
        "  if (k % 500 == 0):\n",
        "    print(k)\n",
        "  # l1 = data[\"Gold\"][k]\n",
        "  # l2 = data[\"Output\"][k]\n",
        "  # if data[\"Correctness\"][k]:\n",
        "  #   positive_indices.append(k)\n",
        "  # else:\n",
        "  #   negative_indices.append(k)\n",
        "  spice_predictions_array.append(spice_output[k]['scores']['All']['f'])\n",
        "  cider_predictions_array.append(cider_output[\"CIDEr\"][k])\n",
        "  meteor_predictions_array.append(meteor_scores[k])\n",
        "  rouge_predictions_array.append(rouge_scores[1][k])\n",
        "\n",
        "# print(count)\n",
        "# print(len(counter))\n",
        "# # x = len(data[\"q_text\"])\n",
        "print(\"SPICE==============\")\n",
        "print(np.average(spice_predictions_array))\n",
        "print(\"CIDEr==============\")\n",
        "print(np.average(cider_predictions_array)/10)\n",
        "print(\"METEOR==============\")\n",
        "print(np.average(meteor_predictions_array))\n",
        "print(\"ROUGE==============\")\n",
        "print(np.average(rouge_predictions_array))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aatdVDDw1dpi"
      },
      "source": [
        "sts_bert_output = [web_model.predict([(data['gold'][i], data['output'][i])])[0] for i in range(len(data['input']))]\n",
        "print(\"STS-BERT===========\")\n",
        "print(np.average(sts_bert_output)/5)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}